import { Injectable } from '@nestjs/common';
import type { DocumentChunk } from '../entities/document-chunk.entity';
import type {
  EmbeddingGeneratorPort,
  EmbeddingConfig,
  BatchEmbeddingResult,
} from '../ports/embedding-generator.port';
import type {
  VectorSearchPort,
  SemanticSearchResult,
  VectorSearchOptions,
} from '../ports/vector-search.port';
import type { DocumentChunkRepositoryPort } from '../ports/document-chunk-repository.port';

/**
 * Opciones para generaci칩n de embeddings de documento
 */
export interface DocumentEmbeddingOptions {
  /** Configuraci칩n de embeddings */
  embeddingConfig?: Partial<EmbeddingConfig>;

  /** Si debe reemplazar embeddings existentes */
  replaceExisting?: boolean;

  /** Procesar en lotes de este tama침o */
  batchSize?: number;

  chunkFilters?: {
    /** Tipos de chunks a procesar */
    chunkTypes?: string[];

    /** 칈ndices de chunks espec칤ficos */
    chunkIndices?: number[];

    /** Tama침o m칤nimo de contenido */
    minContentLength?: number;
  };
}

/**
 * Resultado del procesamiento de embeddings de documento
 */
export interface DocumentEmbeddingResult {
  /** ID del documento procesado */
  documentId: string;

  /** Resultado del procesamiento en lotes */
  batchResults: BatchEmbeddingResult[];

  /** N칰mero total de chunks procesados */
  totalChunksProcessed: number;

  /** N칰mero de chunks que ya ten칤an embeddings */
  chunksSkipped: number;

  /** N칰mero de chunks con errores */
  chunksWithErrors: number;

  /** Tiempo total de procesamiento */
  totalProcessingTimeMs: number;

  /** Costo estimado (si est치 disponible) */
  estimatedCost?: {
    totalTokens: number;
    costPerToken?: number;
    totalCost?: number;
  };

  /** Errores encontrados */
  errors?: string[];
}

/**
 * Servicio de dominio para gesti칩n de embeddings de documentos
 *
 * Coordina la generaci칩n de embeddings para chunks y la b칰squeda vectorial
 */
@Injectable()
export class DocumentEmbeddingService {
  constructor(
    private readonly embeddingGenerator: EmbeddingGeneratorPort,
    private readonly vectorSearch: VectorSearchPort,
    private readonly chunkRepository: DocumentChunkRepositoryPort,
  ) {}

  /**
   * Genera embeddings para todos los chunks de un documento
   *
   * @param documentId - ID del documento a procesar
   * @param options - Opciones de procesamiento
   */
  async generateDocumentEmbeddings(
    documentId: string,
    options: DocumentEmbeddingOptions = {},
  ): Promise<DocumentEmbeddingResult> {
    const startTime = Date.now();

    try {
      // 1. Obtener chunks del documento
      const chunksResult =
        await this.chunkRepository.findByDocumentId(documentId);
      let chunks = chunksResult.chunks;

      if (chunks.length === 0) {
        throw new Error(
          `No se encontraron chunks para el documento ${documentId}`,
        );
      }

      // 2. Aplicar filtros si se especificaron
      chunks = this.applyChunkFilters(chunks, options.chunkFilters);

      // 3. Filtrar chunks que ya tienen embeddings (si no se debe reemplazar)
      if (!options.replaceExisting) {
        chunks = this.filterChunksWithoutEmbeddings(chunks);
        // chunks = await this.filterChunksWithoutEmbeddings(chunks);
      }

      // 4. Validar textos antes de procesar
      const validChunks = chunks.filter((chunk) =>
        this.embeddingGenerator.validateText(chunk.content),
      );

      if (validChunks.length === 0) {
        throw new Error('No hay chunks v치lidos para procesar embeddings');
      }

      // 5. Procesar en lotes
      const batchSize = options.batchSize || 20; // OpenAI permite hasta 2048 inputs
      const batchResults: BatchEmbeddingResult[] = [];
      let totalChunksProcessed = 0;
      let chunksWithErrors = 0;
      const errors: string[] = [];

      for (let i = 0; i < validChunks.length; i += batchSize) {
        const batch = validChunks.slice(i, i + batchSize);
        const texts = batch.map((chunk) => chunk.content);

        try {
          const batchResult =
            await this.embeddingGenerator.generateBatchEmbeddings(
              texts,
              options.embeddingConfig,
            );

          // 6. Almacenar embeddings en la base de datos
          this.storeEmbeddings(batch);
          // await this.storeEmbeddings(batch, batchResult);

          batchResults.push(batchResult);
          totalChunksProcessed += batchResult.totalEmbeddings;
        } catch (error) {
          const errorMessage =
            error instanceof Error ? error.message : 'Unknown error';
          errors.push(
            `Error procesando lote ${i / batchSize + 1}: ${errorMessage}`,
          );
          chunksWithErrors += batch.length;
        }
      }

      const totalProcessingTimeMs = Date.now() - startTime;

      // 7. Calcular estad칤sticas finales
      const totalTokens = batchResults.reduce(
        (sum, result) => sum + result.totalTokensUsed,
        0,
      );
      const chunksSkipped = chunksResult.chunks.length - validChunks.length;

      return {
        documentId,
        batchResults,
        totalChunksProcessed,
        chunksSkipped,
        chunksWithErrors,
        totalProcessingTimeMs,
        estimatedCost: {
          totalTokens,
          costPerToken: 0.00002, // Precio aproximado de text-embedding-3-small
          totalCost: totalTokens * 0.00002,
        },
        errors: errors.length > 0 ? errors : undefined,
      };
    } catch (error) {
      const errorMessage =
        error instanceof Error ? error.message : 'Unknown error';
      throw new Error(
        `Error generando embeddings para documento ${documentId}: ${errorMessage}`,
      );
    }
  }

  /**
   * Realiza b칰squeda sem치ntica en todos los documentos
   *
   * @param query - Texto de b칰squeda
   * @param options - Opciones de b칰squeda
   */
  async searchDocuments(
    query: string,
    options?: VectorSearchOptions,
  ): Promise<SemanticSearchResult> {
    return this.vectorSearch.searchByText(query, options);
  }

  /**
   * Encuentra chunks similares a uno espec칤fico
   *
   * @param chunkId - ID del chunk de referencia
   * @param options - Opciones de b칰squeda
   */
  async findSimilarChunks(chunkId: string, options?: VectorSearchOptions) {
    return this.vectorSearch.findSimilarChunks(chunkId, options);
  }

  /**
   * Encuentra documentos similares a uno espec칤fico
   *
   * @param documentId - ID del documento de referencia
   * @param options - Opciones de b칰squeda
   */
  async findSimilarDocuments(
    documentId: string,
    options?: VectorSearchOptions,
  ) {
    return this.vectorSearch.findSimilarDocuments(documentId, options);
  }

  /**
   * Verifica si un documento tiene embeddings generados
   *
   * @param documentId - ID del documento a verificar
   */
  async hasEmbeddings(documentId: string): Promise<boolean> {
    // Implementar verificaci칩n en el repositorio
    // Por ahora, asumimos que si hay chunks, podr칤an tener embeddings
    const chunks = await this.chunkRepository.findByDocumentId(documentId);
    return chunks.chunks.length > 0;
  }

  // ============ M칄TODOS PRIVADOS ============

  /**
   * Aplica filtros a los chunks
   */
  private applyChunkFilters(
    chunks: DocumentChunk[],
    filters?: DocumentEmbeddingOptions['chunkFilters'],
  ): DocumentChunk[] {
    if (!filters) return chunks;

    let filtered = chunks;

    if (filters.chunkTypes) {
      filtered = filtered.filter((chunk) =>
        filters.chunkTypes!.includes(chunk.type),
      );
    }

    if (filters.chunkIndices) {
      filtered = filtered.filter((chunk) =>
        filters.chunkIndices!.includes(chunk.chunkIndex),
      );
    }

    if (filters.minContentLength) {
      filtered = filtered.filter(
        (chunk) => chunk.content.length >= filters.minContentLength!,
      );
    }

    return filtered;
  }

  /**
   * Filtra chunks que ya tienen embeddings
   * TODO: Implementar verificaci칩n real con pgvector
   */
  private filterChunksWithoutEmbeddings(
    chunks: DocumentChunk[],
  ): DocumentChunk[] {
    // Por ahora retornamos todos los chunks
    // En la implementaci칩n real, verificar칤amos si ya tienen embeddings en la BD
    return chunks;
  }

  /**
   * Almacena embeddings en la base de datos
   * TODO: Implementar actualizaci칩n real con pgvector
   */
  private storeEmbeddings(
    chunks: DocumentChunk[],
    // batchResult: BatchEmbeddingResult,
  ): void {
    // Por ahora no hacemos nada
    // En la implementaci칩n real, actualizar칤amos la columna embedding de cada chunk
    console.log(`游늵 Almacenando ${chunks.length} embeddings...`);
  }
}
